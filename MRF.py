# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1k45hPogPaP6V88K8foEuNGzSjgPIfvDU
"""

import keras
from keras.layers import Dense, Dropout, Flatten, BatchNormalization,Concatenate,Activation, LSTM, Reshape,TimeDistributed,Concatenate,Conv2DTranspose,UpSampling2D,ConvLSTM2D
from keras.layers.advanced_activations import LeakyReLU
from keras.layers.convolutional import Conv1D, Conv2D, MaxPooling2D,MaxPooling1D,AveragePooling2D,AveragePooling1D
from keras.models import Sequential, Input, Model
from keras.callbacks import ModelCheckpoint,CSVLogger
import h5py as h5
import matplotlib.pyplot as plt
import scipy.io as sio
import numpy as np
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from keras import optimizers
import time
from sklearn.feature_extraction import image
import numpy as np 
import os
import skimage.io as io
import skimage.transform as trans
import numpy as np
from keras.models import *
from keras.layers import *
from keras.optimizers import *
from keras.callbacks import ModelCheckpoint, LearningRateScheduler
from keras import backend as keras
from tensorflow.keras import backend as K
import math
from sklearn.decomposition import PCA
from sklearn.metrics import mean_absolute_error
from skimage.util.shape import *

from google.colab import drive
drive.mount('/content/drive/',force_remount=True)
!ls "/content/drive/My Drive/KCL internship/Data/50_gb/transposed_trials"

#seed
from numpy.random import seed
seed(0)
import tensorflow
tensorflow.random.set_seed(0)

#PARAMETERS

input_type = 'patch' #pixel,patch

train1 = 'ir'
train2 = 'kl'
test = 'abd'

signal_type = 'normal'     #choosen_attn, random, normal

num_components = 40
tissue = 'T1_T2'

PCA_model = True;

signal_length = 2000
skip_size = 1
patch_size = 4
ica = True

#Reading Data 

filepath = '/content/drive/My Drive/KCL internship/Data/50_gb/'
filepath2 = '/content/drive/My Drive/KCL internship/Data/50_gb/transposed_trials/transposed_trials_1/'

f1 = sio.loadmat(filepath+train1+'_t1_t2_ground_truths.mat')
T1_ab=f1['T1_LRI']
T2_ab=f1['T2_LRI']
trial1_ab = h5.File(filepath2+train1+'_trial1_transposed_1.mat','r')
signal_ab=trial1_ab['Noisy_tps'] #Complex | matlab([a,b,c,d]) python([d,c,b,a])

f2 = sio.loadmat(filepath+train2+'_t1_t2_ground_truths.mat')
T1_tk=f2['T1_LRI']
T2_tk=f2['T2_LRI']
trial1_tk = h5.File(filepath2+train2+'_trial1_transposed_1.mat','r')
signal_tk=trial1_tk['Noisy_tps'] #Complex | matlab([a,b,c,d]) python([d,c,b,a])

if signal_type=='normal':
  signal_ab=signal_ab[:,:,0:signal_length]
  signal_tk=signal_tk[:,:,0:signal_length] #1000 previously
  print('Signal_ab shape:',signal_ab.shape)
  print('T1_ab shape:',T1_ab.shape)
  print('T2_ab shape:',T2_ab.shape)

if signal_type=='choosen_attn':
  #filepath0='/content/drive/My Drive/KCL internship/FENG 498/averaged_ir_kl_attn_scores.npy'
  filepath0='/content/drive/My Drive/KCL internship/FENG 498/Variables/T1_T2_patch_conv2D_ica_' + test + '.npy'
  saved_ir_kl_attn_scores=np.load(filepath0)
  sorted_index=np.argsort(saved_ir_kl_attn_scores)[-num_components:][::-1]
  sorted_signal_index=np.sort(sorted_index)

  signal_ab=signal_ab[:,:,sorted_signal_index]
  signal_tk=signal_tk[:,:,sorted_signal_index] 

if signal_type=='random':
  filepath0='/content/drive/My Drive/KCL internship/Some variables/rand_values'+ str(num_components) +'.npy'
  saved_random_scores=np.load(filepath0)
  sorted_index=np.argsort(saved_random_scores)[-num_components:][::-1]
  sorted_signal_index=np.sort(sorted_index)

  signal_ab=signal_ab[:,:,sorted_signal_index]
  signal_tk=signal_tk[:,:,sorted_signal_index]

def get_mag(signal):
  real=[]
  real=signal['real']
  im=[]
  im=signal['imag']
  mag=[]
  mag=np.square(real**2+im**2)
  return mag

#Because of signal is complex, get mag of it
signal_ab = get_mag(signal_ab)
signal_tk = get_mag(signal_tk)

#Crop
signal_ab = signal_ab[55:275,60:260]
T1_ab = T1_ab[55:275,60:260]
T2_ab = T2_ab[55:275,60:260]

signal_tk = signal_tk[55:275,60:260]
T1_tk = T1_tk[55:275,60:260]
T2_tk = T2_tk[55:275,60:260]

def ext_patch(signal,T1,T2,patch_size): 

  signal_patch=[]
  T1_values = image.extract_patches_2d(T1, (patch_size, patch_size))
  T2_values = image.extract_patches_2d(T2, (patch_size, patch_size))

  for i in range(signal.shape[2]):
    c_signal=signal[:,:,i]
    signal_patch.append(image.extract_patches_2d(c_signal, (patch_size, patch_size)))
  return np.array(signal_patch), T1_values , T2_values

#Normalize if PCA is true
if PCA == True:
  signal_max = np.max((np.max(signal_ab), np.max(signal_tk)))
  signal_min = np.min((np.min(signal_ab), np.min(signal_tk)))
  
  T1_ab = (T1_ab-np.min(T1_ab))/(np.max(T1_ab)-np.min(T1_ab))#6000 is max value for T1
  T1_tk = (T1_tk-np.min(T1_ab))/(np.max(T1_ab)-np.min(T1_ab))

  T2_ab = (T2_ab-np.min(T2_ab))/(np.max(T2_ab)-np.min(T2_ab))#2600 is max value for T2
  T2_tk = (T2_tk-np.min(T2_ab))/(np.max(T2_ab)-np.min(T2_ab))

  signal_tk = (signal_tk-signal_min)/(signal_max -signal_min)
  signal_ab = (signal_ab-signal_min)/(signal_max-signal_min)

#Get PCA components
if PCA_model==True:
  signalab_PCA = signal_ab.reshape(-1,2000)
  signaltk_PCA = signal_tk.reshape(-1,2000)
  pca = PCA(n_components=num_components)
  signal_ab = pca.fit_transform(signalab_PCA)
  signal_tk = pca.fit_transform(signaltk_PCA)
 
  signal_ab=signal_ab.reshape(220,200,num_components)
  signal_tk=signal_tk.reshape(220,200,num_components)

if input_type=='pixel':
  signal_ab = signal_ab.reshape(220*200,1,signal_ab.shape[2]) #(220*200,1,signal_abd.shape[2])
  signal_tk = signal_tk.reshape(220*200,1,signal_tk.shape[2])

  T1_ab=T1_ab.reshape(220*200,1)
  T1_tk=T1_tk.reshape(220*200,1)

  T2_ab=T2_ab.reshape(220*200,1)
  T2_tk=T2_tk.reshape(220*200,1)  
  print('signal_ab shape:',signal_ab.shape)

if input_type=='patch': 
  signal_ab_p,T1_ab,T2_ab = ext_patch(signal_ab,T1_ab,T2_ab,patch_size) #signal_ab_p,T1_ab,T2_ab = ext_patch(signal_ab,T1_ab,T2_ab,patch_size) 
  signal_ab_p = np.moveaxis(signal_ab_p, 0, -1)
  del signal_ab
  signal_tk_p,T1_tk,T2_tk = ext_patch(signal_tk,T1_tk,T2_tk,patch_size) #signal_tk_p,T1_tk,T2_tk = ext_patch(signal_tk,T1_tk,T2_tk,patch_size)
  signal_tk_p = np.moveaxis(signal_tk_p, 0, -1)
  del signal_tk
  print('signal_ab shape:',signal_tk_p.shape)

if input_type=='patch':
  signal = np.concatenate([signal_ab_p,signal_tk_p]) 
  del signal_ab_p, signal_tk_p
  T1_values= np.concatenate([T1_ab,T1_tk])
  del T1_ab
  del T1_tk
  T2_values= np.concatenate([T2_ab,T2_tk])
  del T2_ab
  del T2_tk
  
if input_type=='pixel':
  signal = np.concatenate([signal_ab,signal_tk]) 
  T1_values= np.concatenate([T1_ab,T1_tk])
  T2_values= np.concatenate([T2_ab,T2_tk])

#normalize data  (x - x_min)/(x_max - x_min)
T1_values = (T1_values-np.min(T1_values))/(np.max(T1_values)-np.min(T1_values))#6000 is max value for T1
T2_values = (T2_values-np.min(T2_values))/(np.max(T2_values)-np.min(T2_values))#2600 is max value for T2

signal = (signal-np.min(signal))/(np.max(signal)-np.min(signal))
print('Signal max:',np.max(signal))

if input_type=='pixel':
  if tissue=='T1':
    #THIS IS FOR T1
    labels = T1_values
    labels=np.swapaxes(labels,0,1)
    labels=np.swapaxes(labels,1,2)
    model_output_size = 1
    #del T1_values

  elif tissue=='T2':
    #THIS IS FOR T1
    labels = T2_values
    labels=np.swapaxes(labels,0,1)
    labels=np.swapaxes(labels,1,2)
    model_output_size = 1
    #del T2_values

  elif tissue=='T1_T2':
    labels = np.array([T1_values, T2_values]) #for T1_T2
    labels=np.swapaxes(labels,0,1)
    labels=np.swapaxes(labels,1,2)
    print('Label shape:',labels.shape)
    model_output_size = 2
    #del T1_values, T2_values 

elif input_type=='patch':
  if tissue=='T1':
    #THIS IS FOR T1
    labels = T1_values
    labels=np.swapaxes(labels,0,1)
    labels=np.swapaxes(labels,1,2)
    labels=np.swapaxes(labels,2,3)
    model_output_size = 1
    #del T1_values

  elif tissue=='T2':
    #THIS IS FOR T1
    labels = T2_values
    labels=np.swapaxes(labels,0,1)
    labels=np.swapaxes(labels,1,2)
    labels=np.swapaxes(labels,2,3)
    model_output_size = 1
    #del T2_values

  elif tissue=='T1_T2':
    labels = np.array([T1_values, T2_values]) #for T1_T2
    labels=np.swapaxes(labels,0,1)
    labels=np.swapaxes(labels,1,2)
    labels=np.swapaxes(labels,2,3)
    model_output_size = 2
    #del T1_values, T2_values 

print('Label shape:',labels.shape)
print('Signal shape:',signal.shape)

if input_type=='pixel':
  input_shape=(signal.shape[1],signal.shape[2])
if input_type=='patch':
  input_shape=(signal.shape[1],signal.shape[2],signal.shape[3])

def hoppe_last():
  inputs = keras.Input((input_shape))
  x = keras.layers.Reshape((20,200))(inputs)
  x = keras.layers.LSTM(300, return_sequences=True)(x)
  x = keras.layers.BatchNormalization()(x)
  x = keras.layers.Activation('relu')(x)
  x = keras.layers.Flatten()(x)
  x = keras.layers.Dense(2000)(x)
  x = keras.layers.BatchNormalization()(x)
  x = keras.layers.Activation('relu')(x)
  x = keras.layers.Dense(1333)(x)
  x = keras.layers.BatchNormalization()(x)
  x = keras.layers.Activation('relu')(x)
  x = keras.layers.Dense(666)(x)
  x = keras.layers.BatchNormalization()(x)
  x = keras.layers.Activation('relu')(x)
  x = keras.layers.Dense(2)(x)
  x = keras.layers.BatchNormalization()(x)
  x = keras.layers.Activation('relu')(x)  
  return keras.models.Model(inputs = inputs, outputs = x)

def conv1D(spatial_attention = False, channel_attention = False):
  inputs = keras.Input((input_shape))
  if ica==True: #ICA
    x = channel_attn_1D(inputs, 2000, reduction=4)

  x = keras.layers.Conv1D(32, 3, padding = 'same', activation='relu')(x)
  x = keras.layers.Conv1D(64, 3, padding = 'same', activation='relu')(x)

  if channel_attention: #Channel attention
    x = channel_attn_1D(x, 64, reduction=4)

  if spatial_attention: #Spatial attention
    x = spatial_attn_1D(x, 64, 3) 

  x = keras.layers.Conv1D(128, 3, padding = 'same', activation='relu')(x)
  x = keras.layers.Conv1D(64, 3, padding = 'same', activation='relu')(x)

  x = keras.layers.Dense(model_output_size, activation = 'relu')(x)

  return keras.models.Model(inputs = inputs, outputs = x)

def channel_attn_1D(x, nb_filter, reduction):

  avg_pl = keras.layers.AveragePooling1D(pool_size=1)(x)
  avg_pl = keras.layers.Activation('relu')(avg_pl)

  max_pl = keras.layers.MaxPooling1D(pool_size=1)(x)
  max_pl = keras.layers.Activation('relu')(max_pl)

  dense1 = keras.layers.Dense(nb_filter//reduction)
  dense2 = keras.layers.Dense(nb_filter)

  avg_pl_out = dense1(avg_pl)
  avg_pl_out = dense2(avg_pl_out)

  max_pl_out = dense1(max_pl)
  max_pl_out = dense2(max_pl_out)

  ca = keras.layers.add([avg_pl_out, max_pl_out])
  ca = keras.layers.Activation('sigmoid')(ca)

  return keras.layers.multiply([x, ca])

def spatial_attn_1D(sp_input, nb_filter, kernel_size=3):
  fs_avg=keras.layers.AveragePooling1D(pool_size = 1)(sp_input)
  fs_max=keras.layers.MaxPooling1D(pool_size = 1)(sp_input)
  con=keras.layers.Concatenate(axis=2)([fs_avg,fs_max])
  conv=keras.layers.Conv1D(nb_filter, kernel_size , padding='same')(con) #Filter size was specified as 7x7 
  act_sig=keras.layers.Activation('sigmoid')(conv) #Ms(F) Spatial Attention

  return keras.layers.multiply([sp_input, act_sig])

def conv2D(spatial_attention = False, channel_attention = False):
  inputs = keras.Input((patch_size, patch_size, signal.shape[3]))
  
  if ica==True: #ICA
    x = channel_attn_2D(inputs, signal.shape[3], reduction=4)

  x = keras.layers.Conv2D(32, 3, padding = 'same', activation='relu')(x)
  x = keras.layers.Conv2D(64, 3, padding = 'same', activation='relu')(x)

  if channel_attention: #Channel attention
    x = channel_attn_2D(x, 64, reduction=4)

  if spatial_attention: #Spatial attention
    x = spatial_attn_2D(x, 64, 3) 

  x = keras.layers.Conv2D(128, 3, padding = 'same', activation='relu')(x)
  x = keras.layers.Conv2D(64, 3, padding = 'same', activation='relu')(x)

  x = keras.layers.Dense(model_output_size, activation = 'relu')(x)

  return keras.models.Model(inputs = inputs, outputs = x)

#referance paper: https://arxiv.org/pdf/1807.06521v2.pdf
def channel_attn_2D(x, nb_filter, reduction):

  avg_pl = keras.layers.AveragePooling2D(pool_size=patch_size)(x)
  avg_pl = keras.layers.Activation('relu')(avg_pl)

  max_pl = keras.layers.MaxPooling2D(pool_size=patch_size)(x)
  max_pl = keras.layers.Activation('relu')(max_pl)

  dense1 = keras.layers.Dense(nb_filter//reduction)
  dense2 = keras.layers.Dense(nb_filter)

  avg_pl_out = dense1(avg_pl)
  avg_pl_out = dense2(avg_pl_out)

  max_pl_out = dense1(max_pl)
  max_pl_out = dense2(max_pl_out)

  ca = keras.layers.add([avg_pl_out, max_pl_out])
  ca = keras.layers.Activation('sigmoid')(ca)

  return keras.layers.multiply([x, ca])

def spatial_attn_2D(sp_input, nb_filter, kernel_size=3):
  fs_avg=keras.layers.AveragePooling2D(pool_size = patch_size)(sp_input)
  fs_max=keras.layers.MaxPooling2D(pool_size = patch_size)(sp_input)
  con=keras.layers.Concatenate(axis=3)([fs_avg,fs_max])
  conv=keras.layers.Conv2D(nb_filter, kernel_size , padding='same')(con) #Filter size was specified as 7x7 
  act_sig=keras.layers.Activation('sigmoid')(conv) #Ms(F) Spatial Attention

  return keras.layers.multiply([sp_input, act_sig])

import keras
from keras.callbacks import ModelCheckpoint

model = conv2D(spatial_attention = False, channel_attention = False)

name = 'deneme'+str(num_components)+'_'+signal_type
model_name = tissue + '_' + input_type + '_' + name +'_test_'+test
 
lr = 0.0002
decay=0.0
batch_size = 512
num_epoch=200

model.compile(optimizer = keras.optimizers.adam(lr = lr, decay = decay),loss='mean_squared_error',metrics=['mean_absolute_error']) #fe_lr
model.summary()

filepath='/content/drive/My Drive/KCL internship/FENG 498/Ebru/models/' + model_name + '.hdf5'
checkpoint = ModelCheckpoint(filepath, monitor='val_mean_absolute_error', verbose=1, save_best_only=True, mode='auto')
earlystopping = keras.callbacks.EarlyStopping(monitor='val_mean_absolute_error', mode='auto', patience=15, verbose=1)
callbacks_list = [checkpoint, earlystopping]

hist = model.fit(signal, labels, validation_split=0.3, epochs=num_epoch, batch_size=batch_size, callbacks=callbacks_list)

# summarize history for loss
plt.plot(hist.history['loss'])
plt.plot(hist.history['val_loss'])
plt.title('model_loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['loss','val_loss'], loc='upper left')
plt.show()

"""import keras
from keras.models import load_model  
name='conv2D_ICA'
model_name = tissue + '_' + input_type + '_' + name +'_'
model = load_model('/content/drive/My Drive/KCL internship/FENG 498/models/' + model_name + '.hdf5')
attn_score_layer = Model(inputs=model.input, outputs=model.get_layer(index=8).output)
attn_score_layer.summary()

attn_scores=attn_score_layer.predict(signal)
print(attn_scores[1,0,:])

attn_scores=attn_scores.reshape(-1,2000);
print(attn_scores.shape)
mean_of_scores=np.mean(attn_scores,axis = 0) 
print(mean_of_scores.shape)
plt.plot(mean_of_scores)

filepath='/content/drive/My Drive/KCL internship/FENG 498/averaged_ir_kl_attn_scores'
saved_ir_kl_attn_scores=np.save(filepath, mean_of_scores)
"""